<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>机器学习</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-default { background-color: rgba(84, 72, 49, 0.08); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1ddf51ad-9782-8066-bb7d-cca3677423fd" class="page sans"><header><h1 class="page-title">机器学习</h1><p class="page-description"></p></header><div class="page-body"><p id="21ff51ad-9782-80a1-b353-f8dcd86a9c90" class="">Artificial Intelligence</p><p id="1ddf51ad-9782-80e9-b207-d195fb5185b1" class="">机器学习是实现人工智能的一种方法，深度学习是一种实现机器学习的技术。</p><p id="1ddf51ad-9782-8045-9f47-c0b925706d6c" class="">机器学习：使用算法来解析数据，从中学习，然后对真实世界中的事件做出决策和预测，比如垃圾邮件检测，房价预测。</p><p id="1ddf51ad-9782-80d0-8906-d981de7efa12" class="">深度学习：模仿人类神经网络，建立模型，进行数据分析。比如，人脸识别，语义理解、无人驾驶。</p><p id="20ef51ad-9782-80bc-99f4-e9babdf396e7" class="">
</p><p id="1ddf51ad-9782-8099-8d21-ca21718cfc5e" class=""><strong>Regression: The function outputs a scalar.</strong></p><p id="20ef51ad-9782-80f0-a893-d152f18f1e0d" class=""><strong>回归：该函数输出一个标量。</strong></p><p id="20ef51ad-9782-80b6-a7de-e1b096ef9a59" class=""><strong>概念解释：</strong></p><ul id="20ef51ad-9782-804b-b992-fb808923565b" class="bulleted-list"><li style="list-style-type:disc"><strong>回归 (Regression)：</strong> 这是机器学习中<strong>监督学习</strong>的一种主要类型。回归任务的目标是基于输入数据（特征）来预测一个<strong>连续的数值</strong>。</li></ul><ul id="20ef51ad-9782-80ec-91f8-e7320b0acc3c" class="bulleted-list"><li style="list-style-type:disc"><strong>标量 (Scalar)：</strong> 在数学和计算机科学中，标量指的是一个<strong>单一的数值</strong>，与向量（多个数值组成的数组）相对。它只有大小，没有方向。</li></ul><ul id="20ef51ad-9782-802f-a8be-d50e368023b2" class="bulleted-list"><li style="list-style-type:disc"><strong>“输出一个标量”的含义：</strong> 这句话精炼地概括了回归问题的核心特征：<strong>回归模型最终预测的结果是一个单一的、连续的数值。</strong></li></ul><p id="20ef51ad-9782-80b0-b862-fe2eb5501367" class=""><strong>关键点解释：</strong></p><ol type="1" id="20ef51ad-9782-803a-860c-cf42c806ed44" class="numbered-list" start="1"><li><strong>预测连续值：</strong> 与<strong>分类 (Classification)</strong> 任务预测离散的类别标签（如“猫/狗”、“垃圾邮件/正常邮件”、“0-9数字”）不同，回归预测的是可以在一定范围内取任意实数值的结果。</li></ol><ol type="1" id="20ef51ad-9782-80f6-8c0d-c31998818673" class="numbered-list" start="2"><li><strong>例子：</strong><ul id="20ef51ad-9782-80c4-8fc7-f6ea21a55392" class="bulleted-list"><li style="list-style-type:disc">预测房价（输出：一个具体的价格数值，如 450, 000元）</li></ul><ul id="20ef51ad-9782-800a-974b-dbfcc79175a6" class="bulleted-list"><li style="list-style-type:disc">预测温度（输出：一个具体的摄氏度数值，如 25.3°C）</li></ul><ul id="20ef51ad-9782-804b-8522-e02a680fc22b" class="bulleted-list"><li style="list-style-type:disc">预测股票价格（输出：一个具体的股价数值，如 152.78美元）</li></ul><ul id="20ef51ad-9782-80d6-8328-ef813d217cf9" class="bulleted-list"><li style="list-style-type:disc">预测销售额（输出：一个具体的销售额数值，如 120, 500元）</li></ul></li></ol><ol type="1" id="20ef51ad-9782-804c-a7e1-c01df2c18740" class="numbered-list" start="3"><li><strong>函数：</strong> 这里的“函数”指的就是训练好的<strong>回归模型</strong>。你给它输入新的数据（比如房屋的面积、位置、房龄等特征），它就会计算并输出一个预测的标量值（比如预测的房价）。</li></ol><p id="20ef51ad-9782-808d-9437-cc17ee967c74" class="">常见回归算法：如线性回归、决策树回归、神经网络回归等</p><p id="20ef51ad-9782-8091-ad4e-ff2dc62dcd59" class="">
</p><p id="20ef51ad-9782-80a8-968f-c1a214ade237" class="">Classification:Given options(classes),the function outputs the correct one.</p><p id="20ef51ad-9782-806b-b1dd-fc9a3d3283d6" class=""> 分类：给定选项（类别），该函数输出正确的那一个。</p><ul id="20ef51ad-9782-802a-8ed9-d71abceca04a" class="bulleted-list"><li style="list-style-type:disc"><strong>分类 (Classification)：</strong> 这是机器学习中<strong>监督学习</strong>的另一种主要类型（与回归并列）。分类任务的目标是基于输入数据（特征）来预测该输入数据<strong>所属的离散类别或标签</strong>。</li></ul><ul id="20ef51ad-9782-80ff-ab76-c731a6924317" class="bulleted-list"><li style="list-style-type:disc"><strong>选项/类别 (Options/Classes)：</strong> 指的是问题定义好的、有限的、互斥的可能结果集合。例如：<code><strong>[&quot;垃圾邮件&quot;, &quot;正常邮件&quot;]</strong></code>, <code><strong>[&quot;猫&quot;, &quot;狗&quot;, &quot;鸟&quot;]</strong></code>, <code><strong>[&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;]</strong></code>。</li></ul><ul id="20ef51ad-9782-80f9-b0a6-fc07894fdbba" class="bulleted-list"><li style="list-style-type:disc"><strong>“输出正确的那一个”的含义：</strong> 这句话点明了分类问题的核心：模型需要从预定义的几个类别中，<strong>选择并输出输入数据最可能属于的那个类别标签</strong>。</li></ul><ul id="20ef51ad-9782-8084-8858-e873db28c913" class="bulleted-list"><li style="list-style-type:disc"><strong>函数：</strong> 这里的“函数”指的就是训练好的<strong>分类模型</strong>。你给它输入新的数据（比如一封邮件的文本内容、一张图片的像素、一个病人的检查指标），它就会判断并输出一个预测的类别标签（比如“垃圾邮件”、“猫”、“良性肿瘤”）</li></ul><p id="214f51ad-9782-80a9-abac-e7f0d0e0860f" class="">
</p><p id="214f51ad-9782-80fa-a7bf-d6634cdde36b" class=""><strong>Structured Learning: Create something with structure (image,document)</strong></p><p id="214f51ad-9782-8019-a916-c16816815dd1" class=""><strong>结构化学习</strong></p><p id="214f51ad-9782-80ce-8c5e-d1ba136b7d74" class="">
</p><p id="214f51ad-9782-80c5-8407-f605f5611e90" class=""><strong><span style="border-bottom:0.05em solid">1.Function with Unknown Parameters</span></strong></p><figure id="214f51ad-9782-8019-87fc-d9a94b52570e" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>b</mi><mo>+</mo><mi>w</mi><mi>x</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">y=b+ wx1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">x</span><span class="mord">1</span></span></span></span></span></div></figure><p id="214f51ad-9782-8018-b333-ea6484ea368a" class="">Model（模型）                               y = b+wx1             based on domain knowledge(基于领域知识)</p><p id="214f51ad-9782-8095-9680-e72c01cf753a" class="">y:no.of views on 2/26,    x1:no. of views on 2/25;</p><p id="214f51ad-9782-807d-94ea-d1e1f2f97f00" class="">w and b are unknown parameters(learn from data)  </p><p id="214f51ad-9782-802a-87c8-e9e6ab6d0aaf" class="">
</p><p id="214f51ad-9782-80ec-974a-d6de11a4c363" class=""><strong><span style="border-bottom:0.05em solid">2.Define Loss</span></strong></p><p id="214f51ad-9782-8038-a4d9-d1d0bc8447f8" class="">from Training Data. </p><p id="214f51ad-9782-805c-8b3f-d49b79c7745d" class="">Loss is a function of parameters  L(b,w)</p><p id="214f51ad-9782-8066-9d65-ee48d168907e" class="">Loss:</p><p id="214f51ad-9782-8092-b10e-cf1ed5ab276c" class=""><strong>损失函数 L(b,w)</strong></p><p id="214f51ad-9782-80ba-ac2b-ea0cfb30bc57" class="">是模型性能的核心度量，它将<strong>模型参数</strong>（如权重w和偏置b) 与<strong>训练数据的预测误差</strong>建立数学关联。</p><p id="214f51ad-9782-80fe-a2bf-f951ea96bbf6" class="">
</p><table id="21ef51ad-9782-8074-b836-e26ae6127992" class="simple-table"><tbody><tr id="21ef51ad-9782-8056-9e95-de4bd6d117db"><td id="jVji" class=""><strong>特性</strong></td><td id="luP=" class=""><strong>绝对误差 (Absolute Error)</strong></td><td id="r~ci" class=""><strong>平方误差 (Squared Error)</strong></td></tr><tr id="21ef51ad-9782-80c2-a187-f0e41d1194c2"><td id="jVji" class=""><strong>数学形式</strong></td><td id="luP=" class="">|真实值 - 预测值|</td><td id="r~ci" class="">(真实值 - 预测值)²</td></tr><tr id="21ef51ad-9782-8001-a061-d8e92efb1989"><td id="jVji" class=""><strong>异常值敏感度</strong></td><td id="luP=" class="">低（线性增长）</td><td id="r~ci" class="">高（平方放大）</td></tr><tr id="21ef51ad-9782-80b0-a9f4-f4aa50321a68"><td id="jVji" class=""><strong>应用场景</strong></td><td id="luP=" class="">需直观理解误差的实际大小</td><td id="r~ci" class="">强调惩罚大误差（如模型训练）</td></tr><tr id="21ef51ad-9782-8030-ab33-e2903c1baae6"><td id="jVji" class=""><strong>常用衍生指标</strong></td><td id="luP=" class="">MAE（平均绝对误差）</td><td id="r~ci" class="">MSE（均方误差）、RMSE</td></tr></tbody></table><figure id="21ff51ad-9782-8020-9d84-c06fdd1cbf66" class="image"><a href="90afb43abf0b58d36bf7ea22b7da932.png"><img style="width:709.9768676757812px" src="90afb43abf0b58d36bf7ea22b7da932.png"/></a></figure><figure id="21ff51ad-9782-80d0-9768-e2cf9273253c" class="image"><a href="577c332466e1572d8d7a4e173dab33f.png"><img style="width:709.9768676757812px" src="577c332466e1572d8d7a4e173dab33f.png"/></a></figure><p id="21ff51ad-9782-80c2-adf2-d5a26431c7b0" class="">Error surface  <strong>误差曲面</strong>（或<strong>损失曲面</strong>）</p><p id="21ff51ad-9782-80d4-b217-dc6713fba841" class="">误差曲面是<strong>机器学习优化问题</strong>中的核心可视化工具，用于描述<strong>模型参数</strong>与<strong>预测误差</strong>之间的数学关系。其本质是一个高维空间中的几何结构：</p><ol type="1" id="21ff51ad-9782-80eb-a0fa-e13d262323a5" class="numbered-list" start="1"><li><strong>基本定义</strong><ul id="21ff51ad-9782-807a-8db6-de59bdae3f10" class="bulleted-list"><li style="list-style-type:disc"><strong>横轴</strong>：模型参数（如权重 w1,w2,...,wn<em>w</em>1,<em>w</em>2,...,<em>wn</em>）</li></ul><ul id="21ff51ad-9782-8065-adfa-ff55c786399f" class="bulleted-list"><li style="list-style-type:disc"><strong>纵轴</strong>：损失函数值 J(w)<em>J</em>(<strong>w</strong>)（如均方误差、交叉熵）</li></ul><ul id="21ff51ad-9782-80ef-a9fa-d007257a5ef2" class="bulleted-list"><li style="list-style-type:disc"><strong>曲面形态</strong>：每个参数组合对应一个损失值，所有点构成连续曲面</li></ul></li></ol><p id="21ff51ad-9782-8019-8ad9-d39fbfad890c" class="">
</p><p id="21ff51ad-9782-80db-abab-c99debfb6a4d" class="">3.Optimizaton（优化）</p><figure id="21ff51ad-9782-8021-93cc-c0fc676fa4a6" class="image"><a href="1751016737565.png"><img style="width:709.96533203125px" src="1751016737565.png"/></a></figure><p id="21ff51ad-9782-8082-ad96-d557d825a0ff" class=""><strong>Hyperparameters（超参数）：</strong>训练<strong>开始前</strong>人为设定的配置项，控制模型结构和训练过程。</p><p id="224f51ad-9782-802c-bdeb-cbc1fc7a4cdb" class="">超参数是模型训练前设定的， 比如学习率 (Learning Rate)、神经网络的层数和每层神经元数量 (Network Architecture)、训练迭代次数 (Epochs)、正则化强度 (Regularization Strength)、决策树的最大深度 (Max Depth)、支持向量机的核函数 (Kernel) 和 C 值等；而普通参数是训练过程中自动学习的，比如权重值。</p><h3 id="21ff51ad-9782-808e-babd-cf53d0a5f709" class=""><strong>📌 机器学习中的典型超参数</strong></h3><table id="21ff51ad-9782-8032-aa36-c46573c15d20" class="simple-table"><tbody><tr id="21ff51ad-9782-8065-9fae-c83952723f46"><td id="LDM_" class=""><strong>类别</strong></td><td id="TYnI" class=""><strong>常见超参数</strong></td><td id="Ffrt" class=""><strong>作用</strong></td><td id="XfC[" class=""><strong>示例值</strong></td></tr><tr id="21ff51ad-9782-8029-8c07-f3755e3ccf99"><td id="LDM_" class=""><strong>优化策略</strong></td><td id="TYnI" class="">学习率 (Learning Rate)</td><td id="Ffrt" class="">控制参数更新步长</td><td id="XfC[" class="">0.001, 0.0001</td></tr><tr id="21ff51ad-9782-8074-8554-ea109169d77e"><td id="LDM_" class=""></td><td id="TYnI" class="">批量大小 (Batch Size)</td><td id="Ffrt" class="">单次迭代使用的样本数</td><td id="XfC[" class="">32, 64, 128</td></tr><tr id="21ff51ad-9782-80e9-954e-c108a8848c90"><td id="LDM_" class=""><strong>模型结构</strong></td><td id="TYnI" class="">隐藏层数/神经元数</td><td id="Ffrt" class="">决定神经网络复杂度</td><td id="XfC[" class="">层数=4, 神经元数=1024</td></tr><tr id="21ff51ad-9782-80fc-a267-e22f66d71af3"><td id="LDM_" class=""></td><td id="TYnI" class="">嵌入维度 (Embedding Dim)</td><td id="Ffrt" class="">词向量的长度</td><td id="XfC[" class="">768, 1024</td></tr><tr id="21ff51ad-9782-801e-bd73-c6e704764a49"><td id="LDM_" class=""><strong>正则化</strong></td><td id="TYnI" class="">Dropout 比率</td><td id="Ffrt" class="">随机丢弃神经元比例防过拟合</td><td id="XfC[" class="">0.2, 0.5</td></tr><tr id="21ff51ad-9782-80c0-bbdc-ee181cade6f6"><td id="LDM_" class=""></td><td id="TYnI" class="">L2 正则化系数 (λ)</td><td id="Ffrt" class="">惩罚大权重值</td><td id="XfC[" class="">0.01, 0.001</td></tr><tr id="21ff51ad-9782-8065-af18-c84eacac0d67"><td id="LDM_" class=""><strong>训练控制</strong></td><td id="TYnI" class="">训练轮数 (Epochs)</td><td id="Ffrt" class="">数据集完整遍历次数</td><td id="XfC[" class="">10, 50, 100</td></tr><tr id="21ff51ad-9782-8087-a800-df07fb8f7e5c"><td id="LDM_" class=""></td><td id="TYnI" class="">早停耐心值 (Patience)</td><td id="Ffrt" class="">验证集损失无改善时提前停止</td><td id="XfC[" class="">5, 10</td></tr></tbody></table><figure id="21ff51ad-9782-80b8-83c2-d74cbf02fbfe" class="image"><a href="45f95d700255350685591c9b9a3f5d7.png"><img style="width:709.9768676757812px" src="45f95d700255350685591c9b9a3f5d7.png"/></a></figure><p id="21ff51ad-9782-8081-9314-db22d9456a1a" class="">在机器学习和优化问题中，<strong>局部最小值（Local Minima）</strong> 和 <strong>全局最小值（Global Minima）</strong> 是描述损失函数（或误差曲面）关键特征的核心概念。它们的本质区别在于<strong>优化过程中找到的解的质量</strong>。<br/><br/><br/></p><figure id="21ff51ad-9782-803f-9e17-c87a3c55cd43" class="image"><a href="1751018334281.png"><img style="width:709.9768676757812px" src="1751018334281.png"/></a></figure><figure id="21ff51ad-9782-801f-8045-ef5f29223d8e" class="image"><a href="f32058801b1a6a3314c91f65df0cd87.png"><img style="width:709.9768676757812px" src="f32058801b1a6a3314c91f65df0cd87.png"/></a></figure><figure id="222f51ad-9782-80da-8955-d848b941c2e5" class="image"><a href="572b2913895735bef9dd93ab351c69d.png"><img style="width:709.9768676757812px" src="572b2913895735bef9dd93ab351c69d.png"/></a></figure><figure id="222f51ad-9782-80cc-ba03-ed8ea1b1415b" class="image"><a href="a6c1e91c605969ff88ba1b4b6a3136d.png"><img style="width:709.9768676757812px" src="a6c1e91c605969ff88ba1b4b6a3136d.png"/></a></figure><p id="222f51ad-9782-8088-a280-c031736078b4" class="">
</p><figure id="222f51ad-9782-8080-8112-e115411aa525" class="image"><a href="375dead97d56ecb4d8474e92e49dbea.png"><img style="width:709.9768676757812px" src="375dead97d56ecb4d8474e92e49dbea.png"/></a></figure><figure id="223f51ad-9782-8074-b6fb-fffae569b0fe" class="image"><a href="1751333602751.png"><img style="width:709.96533203125px" src="1751333602751.png"/></a></figure><p id="223f51ad-9782-805b-9cd4-d55e2d6e03f0" class="">
</p><figure id="223f51ad-9782-803a-9706-fa9261c72d1d" class="image"><a href="1751334278000.png"><img style="width:709.96533203125px" src="1751334278000.png"/></a></figure><p id="223f51ad-9782-801b-8568-fe7700193b73" class="">
</p><figure id="223f51ad-9782-80b4-b940-d500996f4029" class="image"><a href="1751334724967.png"><img style="width:709.9768676757812px" src="1751334724967.png"/></a></figure><p id="223f51ad-9782-80f1-b241-c898f787431e" class="">
</p><figure id="223f51ad-9782-8068-940b-fc0396493d32" class="image"><a href="image.png"><img style="width:709.9768676757812px" src="image.png"/></a></figure><ul id="223f51ad-9782-8006-89fb-eb8a27ed99ff" class="bulleted-list"><li style="list-style-type:disc"><strong>Piecewise linear curve</strong> = 分段线性曲线</li></ul><ul id="223f51ad-9782-802d-be1f-ea9bf5a962d0" class="bulleted-list"><li style="list-style-type:disc"><strong>Approximate continuous curve</strong> = 逼近连续曲线</li></ul><ul id="223f51ad-9782-8022-a7a2-d6db53cfb3ef" class="bulleted-list"><li style="list-style-type:disc">核心术语 <strong>Piecewise linear approximation</strong> = 分段线性逼近</li></ul><p id="223f51ad-9782-80e7-883e-e6fd8a97d76a" class="">
</p><ol type="1" id="223f51ad-9782-80f7-a0ac-c2bef1b6dbfe" class="numbered-list" start="1"><li><strong>Good approximation</strong> = 良好的逼近效果<p id="223f51ad-9782-8084-803e-cca669e4f4ef" class="">（数学语境中&quot;approximation&quot;固定译作&quot;逼近&quot;，非&quot;近似&quot;）</p></li></ol><ol type="1" id="223f51ad-9782-8035-b62e-e828bf974804" class="numbered-list" start="2"><li><strong>Sufficient pieces</strong> = 足够多的分段<p id="223f51ad-9782-80f4-895e-fb88124288d8" class="">（此处&quot;pieces&quot;特指线性曲线的分段区间）</p></li></ol><p id="223f51ad-9782-808e-95be-fdc7e44ba17f" class="">
</p><figure id="223f51ad-9782-8033-a5c1-ff6e075f8001" class="image"><a href="1751339965945.png"><img style="width:709.9768676757812px" src="1751339965945.png"/></a></figure><p id="223f51ad-9782-80a9-9467-f7430b509db0" class="">
</p><p id="223f51ad-9782-80f8-921c-f70948e94967" class=""> </p><figure id="223f51ad-9782-803d-9b72-fd24837e6e72" class="image"><a href="1751340366294.png"><img style="width:333.98150634765625px" src="1751340366294.png"/></a></figure><p id="223f51ad-9782-8095-b95c-d136e9ebfd51" class="">这是一个<strong>缩放逻辑函数（Scaled Logistic Function）</strong>，在机器学习和统计学中非常常见，尤其用于建模S形曲线（Sigmoid Curve）。下面我将逐步解释其含义、参数、行为以及在机器学习中的应用。<br/><br/><br/></p><ul id="223f51ad-9782-80ee-aeb2-d62b8a88fc2a" class="bulleted-list"><li style="list-style-type:disc"><strong>核心函数</strong>：公式基于标准逻辑函数（Logistic Function），也称为Sigmoid函数：</li></ul><figure id="223f51ad-9782-804f-89b7-c08c7100d6f0" class="image"><a href="1751340767082.png"><img style="width:156.9791717529297px" src="1751340767082.png"/></a></figure><p id="223f51ad-9782-8010-beac-cd5d783c3685" class="">       这是一个S形曲线，输出范围在(0, 1)之间，常用于将任意实数映射到概率或归一化值。</p><ul id="223f51ad-9782-80f6-96a6-d3a1a218639b" class="bulleted-list"><li style="list-style-type:disc"><strong>缩放因子</strong> c<em>c</em>：这里乘以常数 c<em>c</em>，将输出范围从(0, 1)扩展到(0, c)。这允许函数适应更广泛的场景，例如预测值在特定区间（如价格、浓度等）。</li></ul><ul id="223f51ad-9782-80f9-b04f-c3978612c38d" class="bulleted-list"><li style="list-style-type:disc"><strong>自变量部分</strong>：b+<em>wx</em>1 是一个线性组合：<ul id="223f51ad-9782-8041-a772-db5a22adeb4e" class="bulleted-list"><li style="list-style-type:circle">x1：输入特征（自变量），例如在机器学习模型中的一个特征变量。</li></ul><ul id="223f51ad-9782-802a-821e-ec1ff2ef7bc7" class="bulleted-list"><li style="list-style-type:circle">w：权重（Weight），控制 <em>x</em>1 对输出的影响程度。权重越大，曲线变化越陡峭；权重越小，曲线越平缓。</li></ul><ul id="223f51ad-9782-809d-ab0c-dd9b76065bb8" class="bulleted-list"><li style="list-style-type:circle"><em>b</em>：偏置（Bias），控制曲线的水平位置（左/右平移）。</li></ul></li></ul><ul id="223f51ad-9782-80da-8d9b-f8b930d1ea8a" class="bulleted-list"><li style="list-style-type:disc"><strong>完整表达式</strong>：因此，公式可理解为： </li></ul><figure id="223f51ad-9782-8032-bb2b-d2d106f537fc" class="image"><a href="1751340875718.png"><img style="width:356.9560241699219px" src="1751340875718.png"/></a></figure><p id="223f51ad-9782-8050-9aac-dd57900cb273" class="">      其中</p><figure id="223f51ad-9782-80f6-a05a-da48ee3a03e0" class="image"><a href="1751340930302.png"><img style="width:170.97222900390625px" src="1751340930302.png"/></a></figure><p id="223f51ad-9782-80a4-af04-d80844421abb" class="">     是Sigmoid函数。</p><figure id="223f51ad-9782-80c7-95f5-ea14df4ea51a" class="image"><a href="1751341031182.png"><img style="width:709.9537353515625px" src="1751341031182.png"/></a></figure><p id="223f51ad-9782-80af-80f3-e21b0ded4f6f" class="">
</p><p id="223f51ad-9782-8043-aa8d-db63eca23c86" class="">补充知识：自然常数<em><strong>e</strong></em><strong> </strong>的两种显示表达式详解</p><figure id="223f51ad-9782-805f-b9e9-f1e7e9490266" class="image"><a href="1751341722034.png"><img style="width:709.9768676757812px" src="1751341722034.png"/></a></figure><p id="223f51ad-9782-805a-8627-c34d1058c60a" class="">
</p><p id="223f51ad-9782-80e2-8e9a-fd6e06980b69" class="">
</p><figure id="223f51ad-9782-80bd-bc31-d4a14c726510" class="image"><a href="image%201.png"><img style="width:709.9768676757812px" src="image%201.png"/></a></figure><figure id="225f51ad-9782-80b2-be2c-ffd5232ac42b" class="image"><a href="image%201.png"><img style="width:709.9768676757812px" src="image%201.png"/></a></figure><p id="223f51ad-9782-8076-9265-e67d4def6e35" class="">
</p><p id="223f51ad-9782-805b-9c48-f1710fd73dd5" class="">
</p><figure id="223f51ad-9782-8039-98c2-f2d709f26e7c" class="image"><a href="1751349345525.png"><img style="width:709.9768676757812px" src="1751349345525.png"/></a></figure><figure id="223f51ad-9782-809f-a857-d59fbcdcd99c" class="image"><a href="1751350351247.png"><img style="width:709.96533203125px" src="1751350351247.png"/></a></figure><p id="223f51ad-9782-8094-93c7-ef20d13f2eff" class="">
</p><figure id="223f51ad-9782-80a2-8e7a-c9a913fd7547" class="image"><a href="1751350852696.png"><img style="width:709.9768676757812px" src="1751350852696.png"/></a></figure><figure id="223f51ad-9782-80ca-a309-f72a265ab154" class="image"><a href="1751351329921.png"><img style="width:709.9768676757812px" src="1751351329921.png"/></a></figure><figure id="223f51ad-9782-8008-9df3-f27c75410b03" class="image"><a href="1751352379294.png"><img style="width:709.9768676757812px" src="1751352379294.png"/></a></figure><p id="223f51ad-9782-80d4-96c7-edd48ba0bd4c" class="">
</p><figure id="223f51ad-9782-8069-8b4d-cb16b5e6de87" class="image"><a href="1751352846883.png"><img style="width:709.96533203125px" src="1751352846883.png"/></a></figure><p id="223f51ad-9782-802d-b56f-da62763f2037" class="">
</p><figure id="223f51ad-9782-80bc-b476-f31905ae4b58" class="image"><a href="1751353318372.png"><img style="width:709.9768676757812px" src="1751353318372.png"/></a></figure><p id="223f51ad-9782-800b-9c29-fdcc450435c3" class="">补充知识：矩阵与向量</p><figure id="223f51ad-9782-80a5-b143-eaf940dd3e7f" class="image"><a href="1751353478311.png"><img style="width:709.96533203125px" src="1751353478311.png"/></a></figure><p id="223f51ad-9782-80b3-a46b-d12e59377152" class="">
</p><p id="223f51ad-9782-804c-abda-e2e90bb327f8" class="">
</p><figure id="223f51ad-9782-80c3-81c8-dc5aa0264efb" class="image"><a href="1751354406303.png"><img style="width:709.9768676757812px" src="1751354406303.png"/></a></figure><figure id="225f51ad-9782-8069-a0b9-d13d9a1ad6be" class="image"><a href="1751354406303.png"><img style="width:709.9768676757812px" src="1751354406303.png"/></a></figure><p id="223f51ad-9782-8033-a461-ee5ae6b06a34" class="">
</p><p id="223f51ad-9782-803a-be36-c463ff36a28d" class="">补充知识：<strong>Sigmoid</strong> 和 <strong>ReLU</strong> </p><p id="223f51ad-9782-804a-827e-d2fd1632fb71" class="">在机器学习中，<strong>Sigmoid</strong> 和 <strong>ReLU</strong> 是两类核心的<strong>激活函数</strong>（Activation Function），它们为神经网络引入非线性能力，但设计理念和应用场景有本质差异。以下是深度对比：</p><figure id="223f51ad-9782-8063-b34c-d9507724185b" class="image"><a href="1751354775916.png"><img style="width:709.9768676757812px" src="1751354775916.png"/></a></figure><figure id="223f51ad-9782-8090-acb0-ebd3fe9e3ed4" class="image"><a href="1751354815757.png"><img style="width:709.9768676757812px" src="1751354815757.png"/></a></figure><figure id="223f51ad-9782-80cc-a49d-cdf3272c9402" class="image"><a href="1751354925042.png"><img style="width:709.9768676757812px" src="1751354925042.png"/></a></figure><p id="223f51ad-9782-80e9-8a44-f04ba5d3c2c6" class="">
</p><figure id="223f51ad-9782-80f5-af44-d6eec4f2c342" class="image"><a href="1751355072766.png"><img style="width:709.9768676757812px" src="1751355072766.png"/></a></figure><p id="223f51ad-9782-804b-aa33-c04bc82f20b2" class="">
</p><figure id="223f51ad-9782-8073-b20f-d52e22e210ed" class="image"><a href="1751355270808.png"><img style="width:709.9768676757812px" src="1751355270808.png"/></a></figure><p id="223f51ad-9782-80c5-b58d-ec6b62366fd1" class="">
</p><figure id="223f51ad-9782-80a9-9b69-cd10e63d63de" class="image"><a href="1751355657030.png"><img style="width:709.9768676757812px" src="1751355657030.png"/></a></figure><figure id="223f51ad-9782-80be-8b87-ceff262ee392" class="image"><a href="1751358038139.png"><img style="width:709.9884643554688px" src="1751358038139.png"/></a></figure><p id="223f51ad-9782-8097-a282-db43e404e939" class="">
</p><p id="223f51ad-9782-8067-b573-e297946fae86" class="">
</p><figure id="223f51ad-9782-8090-b4b4-d60c09215543" class="image"><a href="1751358413696.png"><img style="width:709.96533203125px" src="1751358413696.png"/></a></figure><p id="223f51ad-9782-8060-b645-c52d1ddd3dd4" class="">
</p><figure id="223f51ad-9782-80a6-afd0-c9324fc771fc" class="image"><a href="1751360852082.png"><img style="width:709.9768676757812px" src="1751360852082.png"/></a></figure><figure id="223f51ad-9782-8051-8dfc-f3946af82ca7" class="image"><a href="91158c210345a3fb97692c063b761b6.png"><img style="width:709.9768676757812px" src="91158c210345a3fb97692c063b761b6.png"/></a></figure><p id="223f51ad-9782-80cc-bae1-e40d8519bd18" class="">
</p><figure id="223f51ad-9782-809e-8fad-d015bc96782b" class="image"><a href="1751363561543.png"><img style="width:709.9768676757812px" src="1751363561543.png"/></a></figure><figure id="223f51ad-9782-804b-b28b-e7226d3b02f8" class="image"><a href="image%202.png"><img style="width:709.9768676757812px" src="image%202.png"/></a></figure><figure id="223f51ad-9782-80bd-9537-d8e3e681fa5f" class="image"><a href="1751363684718.png"><img style="width:709.9768676757812px" src="1751363684718.png"/></a></figure><figure id="223f51ad-9782-80e5-aad8-f180f21351d4" class="image"><a href="1751363720602.png"><img style="width:709.9768676757812px" src="1751363720602.png"/></a></figure><p id="223f51ad-9782-804b-85a8-c2397d836dc3" class="">
</p><p id="223f51ad-9782-803f-96f8-e9dc885e2d98" class="">
</p><figure id="223f51ad-9782-804a-8470-eedc30eb5f77" class="image"><a href="1751364174451.png"><img style="width:709.9768676757812px" src="1751364174451.png"/></a></figure><p id="223f51ad-9782-80b1-8bbf-e90946ff7506" class="">
</p><figure id="223f51ad-9782-808b-88ce-dc2beb1877e7" class="image"><a href="1751365826231.png"><img style="width:709.96533203125px" src="1751365826231.png"/></a></figure><p id="224f51ad-9782-80b8-ab59-f268656be516" class="">
</p><figure id="224f51ad-9782-8056-8699-cd900a0acf51" class="image"><a href="image%203.png"><img style="width:709.9884643554688px" src="image%203.png"/></a></figure><p id="224f51ad-9782-803d-a93e-d58030cad96f" class="">一个epoch 更新了多少次取决于batch size有多大</p><p id="224f51ad-9782-80f9-8aaf-e315ad7d73c1" class="">
</p><figure id="224f51ad-9782-8049-ab25-d54c20d2b78e" class="image"><a href="1751426559629.png"><img style="width:709.9768676757812px" src="1751426559629.png"/></a></figure><p id="224f51ad-9782-80b2-873c-e12061005f9b" class="">两个ReLU函数叠加时，<strong>不是简单地把两个图形在空间上叠加</strong>，而是<strong>在同一个x点上对两个函数值进行代数相加</strong>。<br/><br/></p><p id="224f51ad-9782-809b-b99b-f1f4ebd65688" class=""><br/><br/></p><figure id="224f51ad-9782-8053-9438-d8f82f6df47c" class="image"><a href="1751426930906.png"><img style="width:709.9884643554688px" src="1751426930906.png"/></a></figure><p id="224f51ad-9782-800f-a535-c3925bbdef87" class="">
</p><figure id="224f51ad-9782-8047-99cf-c6a9e7bea3e6" class="image"><a href="1751427426216.png"><img style="width:709.96533203125px" src="1751427426216.png"/></a></figure><p id="224f51ad-9782-80ec-86c8-cb7f9e003498" class="">线性函数→10个ReLU→100个ReLU→1000个ReLU，训练资料上Loss显著降低。</p><p id="224f51ad-9782-803d-b204-f7a9cf1c531d" class="">
</p><figure id="224f51ad-9782-807e-93b6-e6db49246280" class="image"><a href="1751428380052.png"><img style="width:709.96533203125px" src="1751428380052.png"/></a></figure><p id="224f51ad-9782-80e2-ac9a-d0d2caaf0810" class="">
</p><figure id="224f51ad-9782-80a7-9e01-f14b555c948f" class="image"><a href="1751436546232.png"><img style="width:709.9768676757812px" src="1751436546232.png"/></a></figure><p id="224f51ad-9782-8012-8f33-fb56ad4cc519" class="">
</p><figure id="224f51ad-9782-80fc-aecf-edaeec034ea9" class="image"><a href="1a10cf029560a239295d6de66303064.png"><img style="width:720px" src="1a10cf029560a239295d6de66303064.png"/></a></figure><ol type="1" id="224f51ad-9782-8029-a26c-f7ab192d535d" class="numbered-list" start="1"><li><strong>模型结构</strong>：<ul id="224f51ad-9782-805d-a155-e6cf0f01021e" class="bulleted-list"><li style="list-style-type:disc">输入层：过去56天的观看次数（即输入特征维度为56）</li></ul><ul id="224f51ad-9782-80a4-82dc-d497ef2189fe" class="bulleted-list"><li style="list-style-type:disc">隐藏层：每层100个神经元，使用ReLU激活函数</li></ul><ul id="224f51ad-9782-804f-9940-d0e02bff1b39" class="bulleted-list"><li style="list-style-type:disc">输出层：未明确说明，但根据上下文应为回归任务（预测观看次数？）</li></ul></li></ol><ol type="1" id="224f51ad-9782-800b-b764-d49e83df4393" class="numbered-list" start="2"><li><strong>对比配置</strong>：<ul id="224f51ad-9782-809b-b83f-d76c2cfb2f20" class="bulleted-list"><li style="list-style-type:disc"><strong>1层</strong>：输入层 → 100个ReLU → 输出层</li></ul><ul id="224f51ad-9782-804e-87db-edb15363b1bc" class="bulleted-list"><li style="list-style-type:disc"><strong>2层</strong>：输入层 → 100个ReLU → 100个ReLU → 输出层</li></ul><ul id="224f51ad-9782-8011-9642-e6540be1ab73" class="bulleted-list"><li style="list-style-type:disc"><strong>3层</strong>：输入层 → 100个ReLU → 100个ReLU → 100个ReLU → 输出层</li></ul></li></ol><ol type="1" id="224f51ad-9782-805b-a425-d6fa3b0c3c25" class="numbered-list" start="3"><li><strong>评估指标</strong>：<ul id="224f51ad-9782-8045-bea5-cb78a87b83c4" class="bulleted-list"><li style="list-style-type:disc"><strong>损失值（Loss）</strong>：数值越小表示模型预测越准确（单位：千，k = 1000）</li></ul></li></ol><h3 id="224f51ad-9782-8083-b84e-fefab691fe08" class=""><strong>实验结果分析</strong></h3><table id="224f51ad-9782-8051-b1a4-e4c9fcfd2bef" class="simple-table"><tbody><tr id="224f51ad-9782-80b9-a6db-fa4da56eb130"><td id="NhP|" class=""><strong>模型结构</strong></td><td id="bcVy" class=""><strong>2017-2020损失</strong></td><td id="Orrs" class=""><strong>2021损失</strong></td><td id="R_n^" class=""><strong>性能分析</strong></td></tr><tr id="224f51ad-9782-8023-bc53-d9bac2c7f306"><td id="NhP|" class=""><strong>1层网络</strong></td><td id="bcVy" class="">0.28k</td><td id="Orrs" class="">0.43k</td><td id="R_n^" class="">基础模型表现最弱</td></tr><tr id="224f51ad-9782-8018-8c85-ca8ae613384a"><td id="NhP|" class=""><strong>2层网络</strong></td><td id="bcVy" class="">0.18k</td><td id="Orrs" class="">0.39k</td><td id="R_n^" class="">训练损失↓35.7%，测试损失↓9.3%</td></tr><tr id="224f51ad-9782-80a2-92ee-e20eb4b02216"><td id="NhP|" class=""><strong>3层网络</strong></td><td id="bcVy" class="">0.14k</td><td id="Orrs" class="">0.38k</td><td id="R_n^" class="">训练损失↓50%，测试损失↓11.6%</td></tr></tbody></table><figure id="224f51ad-9782-808c-bcc2-f376fffb9bcf" class="image"><a href="1751437406785.png"><img style="width:709.96533203125px" src="1751437406785.png"/></a></figure><p id="224f51ad-9782-8075-8a4e-d0a3cd976c04" class="">
</p><figure id="224f51ad-9782-8020-8094-d10653a71956" class="image"><a href="1751437972126.png"><img style="width:709.9768676757812px" src="1751437972126.png"/></a></figure><p id="224f51ad-9782-803a-87a3-cb369fdbdbea" class="">
</p><figure id="224f51ad-9782-80ae-9723-eb2aa8546c88" class="image"><a href="1751439047890.png"><img style="width:709.96533203125px" src="1751439047890.png"/></a></figure><figure id="224f51ad-9782-809a-9589-cbd6d103c520" class="image"><a href="1751443557339.png"><img style="width:709.9768676757812px" src="1751443557339.png"/></a></figure><figure id="224f51ad-9782-808c-ac1e-c57b8e32ea77" class="image"><a href="1751443362368.png"><img style="width:709.9768676757812px" src="1751443362368.png"/></a></figure><p id="224f51ad-9782-80cd-917d-e19b232dfca3" class="">
</p><figure id="224f51ad-9782-8012-8780-ed582cd6ca23" class="image"><a href="1751443795234.png"><img style="width:709.9768676757812px" src="1751443795234.png"/></a></figure><p id="224f51ad-9782-8058-839f-e6f8fe8a0127" class="">
</p><p id="224f51ad-9782-80f3-8de2-f73c82a524b1" class="">
</p><figure id="224f51ad-9782-8084-b77c-f0d92f705b64" class="image"><a href="1751445499612.png"><img style="width:709.9768676757812px" src="1751445499612.png"/></a></figure><p id="224f51ad-9782-801f-ba45-ed9c12d2a4f9" class="">
</p><figure id="225f51ad-9782-80f0-aa6c-f4698e7b78bf" class="image"><a href="1751446532541.png"><img style="width:709.9768676757812px" src="1751446532541.png"/></a></figure><p id="225f51ad-9782-80c1-99ad-c1c0ccc61044" class="">
</p><figure id="225f51ad-9782-80de-a85b-cf64b054ae8b" class="image"><a href="1751506099791.png"><img style="width:709.96533203125px" src="1751506099791.png"/></a></figure><figure id="225f51ad-9782-804f-bd2c-ed735588b820" class="image"><a href="1751506241189.png"><img style="width:709.9768676757812px" src="1751506241189.png"/></a></figure><figure id="225f51ad-9782-80a7-aed4-fad6e7f06c58" class="image"><a href="1751506346675.png"><img style="width:709.9768676757812px" src="1751506346675.png"/></a></figure><p id="225f51ad-9782-8030-9d98-d3aff356a1c6" class="">
</p><figure id="225f51ad-9782-805e-99c1-ecd0e89074f8" class="image"><a href="1751507129917.png"><img style="width:709.9768676757812px" src="1751507129917.png"/></a></figure><p id="225f51ad-9782-80bc-97b5-f8ff229c9ab1" class="">模型足够复杂，但<strong>优化算法无法定位损失函数中的全局最小值</strong>。此时需要：</p><ol type="1" id="225f51ad-9782-80ca-afa9-ebe740f6b4fc" class="numbered-list" start="1"><li>使用更先进的优化器（如 Adam）</li></ol><ol type="1" id="225f51ad-9782-80d7-871d-cadacfed209d" class="numbered-list" start="2"><li>调整学习率策略（如 Warmup + 衰减）</li></ol><ol type="1" id="225f51ad-9782-80b9-ad31-edae606342a4" class="numbered-list" start="3"><li>改进初始化（如 He 初始化）</li></ol><ol type="1" id="225f51ad-9782-80ca-8c35-c8d880979c52" class="numbered-list" start="4"><li>引入批归一化（BN）稳定优化</li></ol><ol type="1" id="225f51ad-9782-8014-9b4a-d216f05b9267" class="numbered-list" start="5"><li>尝试梯度裁剪避免震荡</li></ol><figure id="225f51ad-9782-8090-9872-f1cd9f37fa27" class="image"><a href="1751507826158.png"><img style="width:709.9768676757812px" src="1751507826158.png"/></a></figure><p id="225f51ad-9782-8074-b857-c142891e78b2" class="">
</p><figure id="225f51ad-9782-80ce-8947-cbc676c99d87" class="image"><a href="1751507870939.png"><img style="width:709.96533203125px" src="1751507870939.png"/></a></figure><figure id="225f51ad-9782-803f-8cfa-e0b5effe5416" class="image"><a href="1751508073193.png"><img style="width:709.9768676757812px" src="1751508073193.png"/></a></figure><p id="225f51ad-9782-8036-abec-dede47617239" class="">
</p><figure id="225f51ad-9782-80ac-bed5-ef7bacbea90b" class="image"><a href="1751510965456.png"><img style="width:709.9768676757812px" src="1751510965456.png"/></a></figure><p id="226f51ad-9782-8095-b2e3-f51416d56327" class="">
</p><figure id="226f51ad-9782-80ff-984c-f1e8928586ef" class="image"><a href="1751594174641.png"><img style="width:709.9768676757812px" src="1751594174641.png"/></a></figure><figure id="226f51ad-9782-80d5-8fd6-df96f5474132" class="image"><a href="1751594246191.png"><img style="width:709.9768676757812px" src="1751594246191.png"/></a></figure><p id="226f51ad-9782-8052-b2f7-e0349f8b2767" class="">
</p><figure id="226f51ad-9782-805a-b2de-c56e1fa6b267" class="image"><a href="1751595854143.png"><img style="width:709.9768676757812px" src="1751595854143.png"/></a></figure><p id="226f51ad-9782-80f5-8837-cb4ceae9d1bb" class="">
</p><ul id="226f51ad-9782-8054-a961-e470b06c6f3a" class="bulleted-list"><li style="list-style-type:disc"><strong>通过对比分析获得深层洞察</strong></li></ul><ul id="226f51ad-9782-8021-b6e1-ceae46f0960a" class="bulleted-list"><li style="list-style-type:disc"><strong>从更浅层网络（或其他模型）入手，因其更易优化</strong></li></ul><ul id="226f51ad-9782-80ce-82a9-fd67b5137042" class="bulleted-list"><li style="list-style-type:disc"><strong>若层数更多的神经网络在训练数据上未能达到更低损失，则存在优化问题</strong></li></ul><ul id="226f51ad-9782-8052-832e-c932e3cfa247" class="bulleted-list"><li style="list-style-type:disc"><strong>解决方案：采用更强大的优化技术</strong></li></ul><p id="226f51ad-9782-80c5-8409-d264bcf6a8fc" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>